# üìù Sumarizador de Artigos com LLM, LangChain e Streamlit

Este projeto consiste em uma aplica√ß√£o web interativa desenvolvida com **Streamlit**, integrando um modelo de linguagem natural (LLM) via **LangChain**, com o objetivo de gerar resumos autom√°ticos de textos extensos. O sistema permite ao usu√°rio colar ou carregar um texto e receber instantaneamente um resumo claro e objetivo.

## üîç Objetivo

Criar uma solu√ß√£o pr√°tica baseada em NLP (Natural Language Processing) que:

- Utilize uma LLM (ex: GPT-3.5-turbo) para processar textos.
- Aplique t√©cnicas de prompt engineering para obter resumos consistentes.
- Ofere√ßa uma interface amig√°vel e intuitiva com Streamlit.
- Demonstre integra√ß√£o de componentes com o framework LangChain.

---

## ‚öôÔ∏è Tecnologias Utilizadas

- **Python 3.10+**
- **Streamlit** ‚Äì Interface web interativa
- **LangChain** ‚Äì Framework para orquestra√ß√£o de LLMs
- **OpenAI GPT-3.5-turbo** ‚Äì Modelo de linguagem para sumariza√ß√£o
- **PromptTemplate / LLMChain** ‚Äì Componentes LangChain
- **Secrets API** ‚Äì Armazenamento seguro da chave de API OpenAI

---

## üß± Estrutura da Aplica√ß√£o

1. **Entrada do usu√°rio:**  
   O usu√°rio insere o texto manualmente por meio de um campo de texto.

2. **Constru√ß√£o do prompt:**  
   Um template personalizado instrui o modelo a gerar um resumo informativo e direto.

3. **Processamento via LangChain:**  
   A chain (`LLMChain`) envia o texto e o prompt para a LLM e obt√©m a resposta.

4. **Resposta:**  
   O resumo √© exibido em tempo real na interface, pronto para ser copiado ou utilizado.

---

## üìÑ Exemplo de C√≥digo

```python
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

prompt = PromptTemplate(
    input_variables=["conteudo"],
    template="""
    Resuma o texto abaixo de forma clara e objetiva, mantendo os pontos principais:

    Texto: {conteudo}

    Resumo:
    """
)

llm = ChatOpenAI(temperature=0.3, model_name="gpt-3.5-turbo")
chain = LLMChain(llm=llm, prompt=prompt)
